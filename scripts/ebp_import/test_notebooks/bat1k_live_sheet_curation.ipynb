{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Description:The script is to read Bat1k sequencing status table and map it to GoaT format before importing into the GoaT database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://docs.google.com/spreadsheets/d/1TctmGGvjI7otqTozBqvckOvhv0WmvHXOODzlzWmsF2M/edit?gid=0#gid=0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GoaT curation spreadsheet link:\n",
    "# https://docs.google.com/spreadsheets/d/1vsV7OTU-BAeOkBSrsESGCHaGuLcFW6U9mUluy6II0tY/edit?gid=0#gid=0\n",
    "\n",
    "# Bat1k sequencing status table:\n",
    "csv_link = \"https://urldefense.proofpoint.com/v2/url?u=https-3A__research.st-2Dandrews.ac.uk_bat1k_goat.csv&amp;d=DwIGaQ&amp;c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&amp;r=ROFPW9s86BDaHzmK9wYUbmvRhmF6aEC2Q3PZs5L7P9o&amp;m=jM-boN6vlSWlPdGLVjQQZzpw7PNs2oKYQHyh4OBVWihTymqJOPdUPpCU0RsiwTjV&amp;s=Ysq_9r0PCehJDGp4j4z0O1CAha0luPXBSU31vqHWH7Y&amp;e=\"\n",
    "\n",
    "# Mapping guide:\n",
    "\"https://docs.google.com/spreadsheets/d/1TctmGGvjI7otqTozBqvckOvhv0WmvHXOODzlzWmsF2M/edit?gid=0#gid=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat1k file successfuly opened. Starting cleanup...\n",
      "Loaded 1469 rows and 10 columns\n",
      "Available columns: ['family', 'species', 'ncbi_taxon_id', 'commonname', 'country of collection', 'collected', 'sequencing', 'assembly', 'annotation', 'goat_summary']\n"
     ]
    }
   ],
   "source": [
    "# Select colums to import\n",
    "columns = [\n",
    "    \"family\",\n",
    "    \"species\",\n",
    "    \"ncbi_taxon_id\",\n",
    "    \"commonname\",\n",
    "    \"country of collection\",\n",
    "    \"collected\",\n",
    "    \"sequencing\",\n",
    "    \"assembly\",\n",
    "    \"annotation\",\n",
    "    \"goat_summary\",\n",
    "]\n",
    "# Read the table from the link\n",
    "df = pd.read_csv(csv_link,\n",
    "                    delimiter=\",\",\n",
    "                    dtype=object,\n",
    "                    usecols=columns,\n",
    "                    )\n",
    "\n",
    "print('bat1k file successfuly opened. Starting cleanup...')\n",
    "\n",
    "# validate the data loading\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(\"Available columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_cleanup(df):\n",
    "    \"\"\"\n",
    "    Cleans up a pandas DataFrame by performing the following actions:\n",
    "    - Replaces empty or whitespace-only strings with NaN.\n",
    "    - Strips leading and trailing spaces from all string values.\n",
    "    - Drops columns and rows where all values are NaN.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    df = df.replace(r\"^ +| +$\", r\"\", regex=True)\n",
    "    df.dropna(how=\"all\", axis=1, inplace=True)\n",
    "    df.dropna(how=\"all\", axis=0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def headers_cleanup(df):\n",
    "    \"\"\"\n",
    "    Cleans up the headers by performing the following actions:\n",
    "    - Replaces spaces with underscores.\n",
    "    - Converts all characters to lowercase.\n",
    "    - Removes parentheses.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        df (pandas.DataFrame): The input DataFrame to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.replace(' ', '_')\n",
    "        .str.replace(r'\\(', '',regex=True)\n",
    "        .str.replace(r'\\)', '',regex=True)\n",
    "        .str.lower()\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat1k file successfuly cleaned. Treating project columns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fchen13\\AppData\\Local\\Temp\\ipykernel_5400\\4126194039.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Clean up the table:\n",
    "df_cleaned = headers_cleanup(table_cleanup(df))\n",
    "\n",
    "print('bat1k file successfuly cleaned. Treating project columns...')\n",
    "\n",
    "# Add a sequencing_status column to the table\n",
    "df_cleaned[\"sequencing_status\"] = df_cleaned[\"goat_summary\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BAT1K.tsv file...\n"
     ]
    }
   ],
   "source": [
    "# Define the BAT1K constant\n",
    "BAT1K = \"BAT1K\"\n",
    "\n",
    "# Create new columns using possible sequencing status\n",
    "possible_seq_status = [\"sample_collected\",\"sample_acquired\",\"in_progress\",\"data_generation\",\"in_assembly\",\"insdc_submitted\",\"open\",\"insdc_open\",\"published\"]\n",
    "for item in possible_seq_status:\n",
    "    if item not in df_cleaned:\n",
    "        df_cleaned[item] = pd.Series(dtype='object')\n",
    "\n",
    "# Assign values to each status column\n",
    "for item in possible_seq_status:\n",
    "    df_cleaned.loc[df_cleaned['sequencing_status'] == item, item] = BAT1K\n",
    "\n",
    "# Populate the status columns with the project names based on the hierarchy of the status\n",
    "df_cleaned.loc[df_cleaned[\"published\"] == BAT1K, \"insdc_open\"] = BAT1K\n",
    "df_cleaned.loc[df_cleaned['insdc_open'] == BAT1K, 'open'] = BAT1K\n",
    "df_cleaned.loc[df_cleaned['open'] == BAT1K, 'in_progress'] = BAT1K\n",
    "df_cleaned.loc[df_cleaned['data_generation'] == BAT1K, 'in_progress'] = BAT1K\n",
    "df_cleaned.loc[df_cleaned['in_assembly'] == BAT1K, 'in_progress'] = BAT1K\n",
    "df_cleaned.loc[df_cleaned['in_progress'] == BAT1K, 'sample_acquired'] = BAT1K\n",
    "df_cleaned.loc[df_cleaned['sample_acquired'] == BAT1K, 'sample_collected'] = BAT1K\n",
    "\n",
    "# Create mandatory columns\n",
    "mandatory_fields = [\"ncbi_taxon_id\", \"species\", \"family\", \"synonym\", \"publication_id\", \"contributing_project_lab\"]\n",
    "\n",
    "for item in mandatory_fields:\n",
    "    if item not in df_cleaned:\n",
    "        df_cleaned[item] = np.nan\n",
    "\n",
    "print(\"Generating BAT1K.tsv file...\")\n",
    "df_cleaned.to_csv(\"tsv/BAT1K_expanded.tsv\",sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
